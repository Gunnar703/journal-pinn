{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import time as timer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import make_folder\n",
    "from forcing_functions import get_function\n",
    "from siren import EarlyStopper, get_4_dof_model, latin_hypercube_1D, system_ode_loss\n",
    "from finite_element_code import set_up_4_dof, get_mck, integrate_rk4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up FE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "x, y, E, nu, rho, a0, a1, fdim, free_indices, ndim, _ = set_up_4_dof()\n",
    "\n",
    "# Construct mass, damping, and stiffness matrices\n",
    "m, c, k = get_mck(x, y, E, nu, rho, a0, a1, free_indices)\n",
    "\n",
    "# Define forcing functions\n",
    "# functions = (\"gaussian\", \"sine\", \"chirp\")\n",
    "functions = (\"chirp\",)\n",
    "\n",
    "# Define datasets - each entry is a list of nodes where data will be given (in addition to ICs)\n",
    "given_data = [[0, 2, 3], [2, 3], [3], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 0\n",
    "t1 = 2.9\n",
    "ntc = 290\n",
    "ntp = int((t1 - t0) * 500)\n",
    "tc = torch.linspace(t0, t1, ntc, device=\"cuda\")\n",
    "tp = latin_hypercube_1D(t0, t1, ntp, device=\"cuda\")\n",
    "\n",
    "alpha = 1e-14  # physics loss weight\n",
    "\n",
    "learning_rate = 1e-4\n",
    "max_iterations = 15_000\n",
    "iterations_til_summary = 1000  # print summary every 1000 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Different Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW SOLVING FUNCTION: chirp\n",
      "GIVEN NODES: [0, 2, 3]\n",
      "torch.cuda.memory_allocated() -> 8549376\n",
      "Iteration 0: L_c = 0.060491 -- L_p = 2.2754e+12 -- E = [6.6948e+06]\n",
      "Iteration 1000: L_c = 0.03719 -- L_p = 8.4525e+11 -- E = [1.8346e+07]\n",
      "Iteration 2000: L_c = 0.026012 -- L_p = 1.1123e+12 -- E = [3.3545e+07]\n",
      "Iteration 3000: L_c = 0.017649 -- L_p = 1.3231e+12 -- E = [4.4252e+07]\n",
      "Iteration 4000: L_c = 0.0035263 -- L_p = 6.8866e+11 -- E = [5.9536e+07]\n",
      "Iteration 5000: L_c = 0.00027337 -- L_p = 3.9387e+10 -- E = [6.7666e+07]\n",
      "Iteration 6000: L_c = 0.00026275 -- L_p = 2.9283e+10 -- E = [6.8475e+07]\n",
      "Iteration 7000: L_c = 0.00026083 -- L_p = 2.803e+10 -- E = [6.8486e+07]\n",
      "Iteration 8000: L_c = 0.000261 -- L_p = 2.7519e+10 -- E = [6.8487e+07]\n",
      "Iteration 9000: L_c = 0.00026134 -- L_p = 2.7258e+10 -- E = [6.8488e+07]\n",
      "Iteration 10000: L_c = 0.00026085 -- L_p = 2.6801e+10 -- E = [6.8488e+07]\n",
      "Iteration 11000: L_c = 0.00026077 -- L_p = 2.7167e+10 -- E = [6.8489e+07]\n",
      "Iteration 12000: L_c = 0.00026298 -- L_p = 2.8684e+10 -- E = [6.8488e+07]\n",
      "Iteration 13000: L_c = 0.00026082 -- L_p = 2.7384e+10 -- E = [6.8488e+07]\n",
      "Iteration 14000: L_c = 0.00026077 -- L_p = 2.8388e+10 -- E = [6.849e+07]\n",
      "Training completed in 2304.2 seconds.\n",
      "NOW SOLVING FUNCTION: chirp\n",
      "GIVEN NODES: [2, 3]\n",
      "torch.cuda.memory_allocated() -> 17337344\n",
      "Iteration 0: L_c = 0.08517 -- L_p = 1.7892e+13 -- E = [6.3965e+07]\n",
      "Iteration 1000: L_c = 0.0015803 -- L_p = 1.086e+11 -- E = [6.8006e+07]\n",
      "Iteration 2000: L_c = 0.00028701 -- L_p = 3.8232e+10 -- E = [6.8506e+07]\n",
      "Iteration 3000: L_c = 0.0002503 -- L_p = 2.9315e+10 -- E = [6.8515e+07]\n",
      "Iteration 4000: L_c = 0.00024943 -- L_p = 3.001e+10 -- E = [6.8515e+07]\n",
      "Iteration 5000: L_c = 0.00024682 -- L_p = 2.8036e+10 -- E = [6.8521e+07]\n",
      "Iteration 6000: L_c = 0.00024659 -- L_p = 2.8168e+10 -- E = [6.8521e+07]\n",
      "Iteration 7000: L_c = 0.00024829 -- L_p = 3.0773e+10 -- E = [6.8519e+07]\n",
      "Iteration 8000: L_c = 0.00024859 -- L_p = 2.9499e+10 -- E = [6.8523e+07]\n",
      "Iteration 9000: L_c = 0.00024843 -- L_p = 2.8275e+10 -- E = [6.8519e+07]\n",
      "Iteration 10000: L_c = 0.00025016 -- L_p = 3.6048e+10 -- E = [6.8513e+07]\n",
      "Iteration 11000: L_c = 0.00024934 -- L_p = 3.0568e+10 -- E = [6.8515e+07]\n",
      "Iteration 12000: L_c = 0.00024677 -- L_p = 2.7907e+10 -- E = [6.8522e+07]\n",
      "Iteration 13000: L_c = 0.00024737 -- L_p = 2.8752e+10 -- E = [6.8519e+07]\n",
      "Iteration 14000: L_c = 0.00024636 -- L_p = 2.7958e+10 -- E = [6.852e+07]\n",
      "Training completed in 1743.4 seconds.\n",
      "NOW SOLVING FUNCTION: chirp\n",
      "GIVEN NODES: [3]\n",
      "torch.cuda.memory_allocated() -> 17337344\n",
      "Iteration 0: L_c = 0.10719 -- L_p = 3.1392e+12 -- E = [1.7229e+07]\n",
      "Iteration 1000: L_c = 0.007193 -- L_p = 1.244e+12 -- E = [2.9623e+07]\n",
      "Iteration 2000: L_c = 0.0031892 -- L_p = 1.0969e+12 -- E = [3.3508e+07]\n",
      "Iteration 3000: L_c = 0.0032612 -- L_p = 1.0921e+12 -- E = [3.4034e+07]\n",
      "Iteration 4000: L_c = 0.0032236 -- L_p = 1.0626e+12 -- E = [3.408e+07]\n",
      "Iteration 5000: L_c = 0.0031979 -- L_p = 1.0477e+12 -- E = [3.4127e+07]\n",
      "Iteration 6000: L_c = 0.0032004 -- L_p = 1.0416e+12 -- E = [3.4158e+07]\n",
      "Iteration 7000: L_c = 0.0031968 -- L_p = 1.0382e+12 -- E = [3.4172e+07]\n",
      "Iteration 8000: L_c = 0.0031945 -- L_p = 1.0367e+12 -- E = [3.418e+07]\n",
      "Iteration 9000: L_c = 0.0031924 -- L_p = 1.0362e+12 -- E = [3.4182e+07]\n",
      "Iteration 10000: L_c = 0.0031989 -- L_p = 1.0357e+12 -- E = [3.4183e+07]\n",
      "Iteration 11000: L_c = 0.0031961 -- L_p = 1.0422e+12 -- E = [3.4184e+07]\n",
      "Iteration 12000: L_c = 0.0031972 -- L_p = 1.0375e+12 -- E = [3.4184e+07]\n",
      "Iteration 13000: L_c = 0.0031894 -- L_p = 1.0356e+12 -- E = [3.4184e+07]\n",
      "Iteration 14000: L_c = 0.003199 -- L_p = 1.0362e+12 -- E = [3.4185e+07]\n",
      "Training completed in 1752.7 seconds.\n",
      "NOW SOLVING FUNCTION: chirp\n",
      "GIVEN NODES: []\n",
      "torch.cuda.memory_allocated() -> 17337344\n",
      "Iteration 0: L_c = nan -- L_p = 8.1522e+13 -- E = [1.1876e+07]\n",
      "Iteration 1000: L_c = nan -- L_p = 1.7316e+11 -- E = [5.7972e+06]\n",
      "Iteration 2000: L_c = nan -- L_p = 6.8888e+10 -- E = [4.2129e+06]\n",
      "Iteration 3000: L_c = nan -- L_p = 4.4471e+10 -- E = [3.4979e+06]\n",
      "Iteration 4000: L_c = nan -- L_p = 3.6803e+10 -- E = [3.1874e+06]\n",
      "Iteration 5000: L_c = nan -- L_p = 3.0819e+10 -- E = [3.1255e+06]\n",
      "Iteration 6000: L_c = nan -- L_p = 2.7429e+10 -- E = [3.2638e+06]\n",
      "Iteration 7000: L_c = nan -- L_p = 2.8359e+10 -- E = [3.636e+06]\n",
      "Iteration 8000: L_c = nan -- L_p = 2.0869e+10 -- E = [4.1087e+06]\n",
      "Iteration 9000: L_c = nan -- L_p = 1.8958e+10 -- E = [4.4607e+06]\n",
      "Iteration 10000: L_c = nan -- L_p = 2.7071e+10 -- E = [4.6166e+06]\n",
      "Iteration 11000: L_c = nan -- L_p = 1.4098e+10 -- E = [4.6821e+06]\n",
      "Iteration 12000: L_c = nan -- L_p = 1.3339e+10 -- E = [4.7332e+06]\n",
      "Iteration 13000: L_c = nan -- L_p = 1.2458e+10 -- E = [4.7741e+06]\n",
      "Iteration 14000: L_c = nan -- L_p = 1.9234e+10 -- E = [4.8323e+06]\n",
      "Training completed in 2570.5 seconds.\n"
     ]
    }
   ],
   "source": [
    "for forcing_function in functions:\n",
    "    # Get forcing function\n",
    "    ffun = get_function(\n",
    "        name=forcing_function,\n",
    "        t0=t0,\n",
    "        t1=t1,\n",
    "        amplitude=-1e3,\n",
    "        total_dimensions=ndim,\n",
    "        force_dimension=fdim,\n",
    "    )\n",
    "\n",
    "    # Integrate to get time-histories\n",
    "    displacements, velocities = integrate_rk4(m, c, k, ffun, tc)\n",
    "\n",
    "    # Make folder to store data\n",
    "    force_folder_name = make_folder(\n",
    "        name=os.path.join(\"outputs_inverse\", forcing_function)\n",
    "    )\n",
    "\n",
    "    for node_list in given_data:\n",
    "        print(\"NOW SOLVING FUNCTION:\", forcing_function)\n",
    "        print(\"GIVEN NODES:\", node_list)\n",
    "        print(\"torch.cuda.memory_allocated() ->\", torch.cuda.memory_allocated())\n",
    "\n",
    "        # Get start time\n",
    "        start = timer.time()\n",
    "\n",
    "        # Make folder to store data\n",
    "        node_folder_name = make_folder(\n",
    "            os.path.join(force_folder_name, \"%d_nodes_given\" % len(node_list))\n",
    "        )\n",
    "\n",
    "        # Get maximum displacement - used for normalizing outputs. Only consider amplitude of given nodes.\n",
    "        if len(node_list) > 0:\n",
    "            max_displacement = displacements[node_list].abs().max()\n",
    "        else:\n",
    "            max_displacement = torch.as_tensor(2e-5, device=device)  # estimate\n",
    "\n",
    "        # Create PINN\n",
    "        model = get_4_dof_model()\n",
    "\n",
    "        # Create elastic modulus trainable parameter\n",
    "        E_train = torch.rand(1, device=\"cuda\", dtype=torch.float, requires_grad=True)\n",
    "\n",
    "        # Instantiate optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(model.parameters()) + [E_train],\n",
    "            lr=learning_rate,\n",
    "        )\n",
    "\n",
    "        E_train = E_train.reshape(-1, 1)\n",
    "\n",
    "        # Perform training\n",
    "        csv_filename = os.path.join(node_folder_name, \"loss_history.csv\")\n",
    "        model_save_file = os.path.join(node_folder_name, \"model.pt\")\n",
    "        plot_save_file = os.path.join(node_folder_name, \"result.png\")\n",
    "\n",
    "        zero = torch.zeros((1, 1), device=device)\n",
    "\n",
    "        with open(csv_filename, \"w\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    \"Epoch\",\n",
    "                    \"Collocation Loss\",\n",
    "                    \"Physics Loss\",\n",
    "                    \"Total Loss\",\n",
    "                    \"Alpha\",\n",
    "                    \"E[0]\",\n",
    "                    \"E[1]\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            for step in range(max_iterations):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Shuffle training data - helps a lot with convergence\n",
    "                shuffle_idx_c = torch.randperm(ntc)\n",
    "                shuffle_idx_p = torch.randperm(ntp)\n",
    "\n",
    "                # Enforce Collocation\n",
    "                model_output, _ = model(tc[shuffle_idx_c].reshape(-1, 1))\n",
    "                target = displacements.T[shuffle_idx_c] / max_displacement\n",
    "\n",
    "                zpred, _ = model(zero)\n",
    "\n",
    "                collocation_loss = F.mse_loss(\n",
    "                    model_output[:, node_list], target[:, node_list]\n",
    "                ) + F.mse_loss(zpred, 0 * zpred)\n",
    "\n",
    "                # Enforce Physics\n",
    "                m, c, k = get_mck(x, y, E_train * 1e8, nu, rho, a0, a1, free_indices)\n",
    "\n",
    "                model_output_phys, coords = model(tp[shuffle_idx_p].reshape(-1, 1))\n",
    "                physical_loss = system_ode_loss(\n",
    "                    coords,\n",
    "                    model_output_phys,\n",
    "                    ffun(tp[shuffle_idx_p]),\n",
    "                    m,\n",
    "                    c,\n",
    "                    k,\n",
    "                    max_displacement,\n",
    "                )\n",
    "\n",
    "                # Total loss\n",
    "                loss = collocation_loss + alpha * physical_loss\n",
    "\n",
    "                # Print out an update, save model, + log to file\n",
    "                if step % iterations_til_summary == 0:\n",
    "                    print(\n",
    "                        \"Iteration %d: L_c = %.5g -- L_p = %.5g -- E = [%.5g]\"\n",
    "                        % (step, collocation_loss, physical_loss, E_train[0, 0] * 1e8)\n",
    "                    )\n",
    "                    writer.writerow(\n",
    "                        [\n",
    "                            step,\n",
    "                            collocation_loss.item(),\n",
    "                            physical_loss.item(),\n",
    "                            loss.item(),\n",
    "                            alpha,\n",
    "                            E_train[0, 0] * 1e8,\n",
    "                        ]\n",
    "                    )\n",
    "                    torch.save(model.state_dict(), model_save_file)\n",
    "\n",
    "                # Backpropagate\n",
    "                loss.backward()\n",
    "\n",
    "                # Update model parameters\n",
    "                optimizer.step()\n",
    "\n",
    "        # Training finished.\n",
    "        end = timer.time()\n",
    "        print(\"Training completed in %.5g seconds.\" % (end - start))\n",
    "\n",
    "        # Make plot of the results\n",
    "        u_pred, _ = model(tc.reshape(-1, 1))\n",
    "\n",
    "        fig, ax = plt.subplots(ndim // 2, 2, sharex=True, sharey=True, figsize=(10, 5))\n",
    "\n",
    "        for i in range(ndim // 2):\n",
    "            # Plot solution\n",
    "            ax[i, 0].plot(\n",
    "                tc.cpu(),\n",
    "                displacements[2 * i].cpu(),\n",
    "                color=\"gray\",\n",
    "                alpha=0.4,\n",
    "                label=\"Solution\",\n",
    "            )\n",
    "            ax[i, 1].plot(\n",
    "                tc.cpu(),\n",
    "                displacements[2 * i + 1].cpu(),\n",
    "                color=\"gray\",\n",
    "                alpha=0.4,\n",
    "                label=\"Solution\",\n",
    "            )\n",
    "\n",
    "            # Plot model prediction\n",
    "            ax[i, 0].plot(\n",
    "                tc.cpu(),\n",
    "                u_pred.detach()[:, 2 * i].cpu() * max_displacement.cpu(),\n",
    "                color=\"green\",\n",
    "                label=\"Prediction\",\n",
    "            )\n",
    "            ax[i, 1].plot(\n",
    "                tc.cpu(),\n",
    "                u_pred.detach()[:, 2 * i + 1].cpu() * max_displacement.cpu(),\n",
    "                color=\"green\",\n",
    "                label=\"Prediction\",\n",
    "            )\n",
    "\n",
    "            # Format plots\n",
    "            ax[i, 0].set_ylim(displacements.cpu().min(), displacements.cpu().max())\n",
    "            ax[i, 1].set_ylim(displacements.cpu().min(), displacements.cpu().max())\n",
    "            ax[i, 0].set_ylabel(\"Node %d\" % (2 + i))\n",
    "\n",
    "            if i == 0:\n",
    "                ax[i, 0].set_title(\"X-Displacement (m)\")\n",
    "                ax[i, 1].set_title(\"Y-Displacement (m)\")\n",
    "\n",
    "            if 2 * i in node_list:\n",
    "                # Plot given data\n",
    "                ax[i, 0].plot(\n",
    "                    tc.cpu(),\n",
    "                    displacements[2 * i].cpu(),\n",
    "                    color=\"orange\",\n",
    "                    label=\"Data\",\n",
    "                    marker=\".\",\n",
    "                    markersize=1,\n",
    "                    linestyle=\"None\",\n",
    "                )\n",
    "\n",
    "            if (2 * i + 1) in node_list:\n",
    "                ax[i, 1].plot(\n",
    "                    tc.cpu(),\n",
    "                    displacements[2 * i + 1].cpu(),\n",
    "                    color=\"orange\",\n",
    "                    label=\"Data\",\n",
    "                    marker=\".\",\n",
    "                    markersize=1,\n",
    "                    linestyle=\"None\",\n",
    "                )\n",
    "\n",
    "            # Legend\n",
    "            if i == 0:\n",
    "                ax[i, 1].legend(loc=\"upper center\", ncols=1, bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "        plt.savefig(plot_save_file, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # Delete all unneeded variables\n",
    "        del (\n",
    "            model,\n",
    "            fig,\n",
    "            ax,\n",
    "            u_pred,\n",
    "            start,\n",
    "            end,\n",
    "            optimizer,\n",
    "            loss,\n",
    "            physical_loss,\n",
    "            collocation_loss,\n",
    "            target,\n",
    "            model_output,\n",
    "            shuffle_idx_c,\n",
    "            shuffle_idx_p,\n",
    "            writer,\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
